import os
import json
import re
import time
import random
import atexit
import signal
from base64 import b64decode
from io import BytesIO
from pathlib import Path
from urllib.parse import urljoin

import pandas as pd
from PIL import Image
from playwright.sync_api import (
    sync_playwright,
    Page,
    TimeoutError as PWTimeoutError,
    Error as PWError,
)

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========

INPUT_FILE = Path("–ê–í–¢–û–°–ê–õ–û–ù 11.11.xlsx")
INPUT_SHEET = None
URL_COLUMN = None

OUT_DIR = Path("avito_phones_playwright")
OUT_DIR.mkdir(exist_ok=True)
IMG_DIR = OUT_DIR / "phones"
IMG_DIR.mkdir(exist_ok=True)
DEBUG_DIR = OUT_DIR / "debug"
DEBUG_DIR.mkdir(exist_ok=True)

OUT_JSON = OUT_DIR / "phones_map.json"
PENDING_JSON = OUT_DIR / "pending_review.json"   # –æ—á–µ—Ä–µ–¥—å —Å—Å—ã–ª–æ–∫ ¬´–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ¬ª
PENDING_RECHECK = True                            # –¥–µ–ª–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –ª—ë–≥–∫–∏–π –ø—Ä–æ—Ö–æ–¥ –≤ –∫–æ–Ω—Ü–µ
PENDING_RECHECK_LIMIT = 150                       # –º–∞–∫—Å–∏–º—É–º —Å—Å—ã–ª–æ–∫ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞ –∑–∞ –∑–∞–ø—É—Å–∫
PENDING_RECHECK_WAIT = (3.0, 6.0)                 # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏

SAVE_DATA_URI = True
HEADLESS = False

TEST_TOTAL = 400
CONCURRENCY = 3

CLICK_DELAY = 8
NAV_TIMEOUT = 90_000

USE_PROXY = False
PROXY_HOST = "mproxy.site"
PROXY_PORT = 17518
PROXY_LOGIN = "YT4aBK"
PROXY_PASSWORD = "nUg2UTut9UMU"

PAGE_DELAY_BETWEEN_BATCHES = (2.0, 4.0)
UA = ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
      "AppleWebKit/537.36 (KHTML, like Gecko) "
      "Chrome/120.0.0.0 Safari/537.36")

# === –ß–ï–õ–û–í–ï–ß–ù–û–°–¢–¨ / –ê–ù–¢–ò–ë–ê–ù-–ü–û–í–ï–î–ï–ù–ò–ï ===
HUMAN = {
    "pre_page_warmup_scrolls": (1, 3),
    "scroll_step_px": (250, 900),
    "scroll_pause_s": (0.15, 0.6),
    "hover_pause_s": (0.12, 0.35),
    "pre_click_pause_s": (0.08, 0.22),
    "post_click_pause_s": (0.10, 0.25),
    "mouse_wiggle_px": (4, 12),
    "mouse_wiggle_steps": (2, 5),
    "between_actions_pause": (0.08, 0.25),
    "click_delay_jitter": (CLICK_DELAY * 0.8, CLICK_DELAY * 1.2),
    "randomize_selectors": True,
}

# ========== –•–ï–õ–ü–ï–†–´: —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç—å ==========

def human_sleep(a: float, b: float):
    time.sleep(random.uniform(a, b))

def human_pause_jitter():
    human_sleep(*HUMAN["between_actions_pause"])

def human_scroll_jitter(page: Page, count: int | None = None):
    if count is None:
        count = random.randint(*HUMAN["pre_page_warmup_scrolls"])
    try:
        height = page.evaluate("() => document.body.scrollHeight") or 3000
        for _ in range(count):
            step = random.randint(*HUMAN["scroll_step_px"])
            direction = 1 if random.random() > 0.25 else -1
            y = max(0, min(height, page.evaluate("() => window.scrollY") + step * direction))
            page.evaluate("y => window.scrollTo({top: y, behavior: 'smooth'})", y)
            human_sleep(*HUMAN["scroll_pause_s"])
    except Exception:
        pass

def human_wiggle_mouse(page: Page, x: float, y: float):
    steps = random.randint(*HUMAN["mouse_wiggle_steps"])
    amp = random.randint(*HUMAN["mouse_wiggle_px"])
    for _ in range(steps):
        dx = random.randint(-amp, amp)
        dy = random.randint(-amp, amp)
        try:
            page.mouse.move(x + dx, y + dy)
        except Exception:
            pass
        human_pause_jitter()

def human_hover(page: Page, loc):
    try:
        box = loc.bounding_box()
        if not box:
            return
        cx = box["x"] + box["width"] * random.uniform(0.35, 0.65)
        cy = box["y"] + box["height"] * random.uniform(0.35, 0.65)
        page.mouse.move(cx, cy)
        human_wiggle_mouse(page, cx, cy)
        human_sleep(*HUMAN["hover_pause_s"])
    except Exception:
        pass

# ========== –•–ï–õ–ü–ï–†–´: DOM/—Å—Ç—Ä–∞–Ω–∏—Ü—ã ==========

def safe_get_content(page: Page) -> str:
    try:
        return page.content()
    except PWError:
        time.sleep(0.8)
        try:
            return page.content()
        except PWError:
            return ""

def is_captcha_or_block(page: Page) -> bool:
    try:
        url = page.url.lower()
    except PWError:
        url = ""
    html = safe_get_content(page).lower()
    if "captcha" in url or "firewall" in url:
        return True
    if "–¥–æ—Å—Ç—É–ø —Å –≤–∞—à–µ–≥–æ ip-–∞–¥—Ä–µ—Å–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω" in html:
        return True
    return False

def close_city_or_cookie_modals(page: Page):
    selectors = [
        "button[aria-label='–ó–∞–∫—Ä—ã—Ç—å']",
        "button[data-marker='modal-close']",
        "button[class*='close']",
        "button:has-text('–ü–æ–Ω—è—Ç–Ω–æ')",
        "button:has-text('–•–æ—Ä–æ—à–æ')",
        "button:has-text('–°–æ–≥–ª–∞—Å–µ–Ω')",
        "button:has-text('–ü—Ä–∏–Ω—è—Ç—å')",
    ]
    for sel in selectors:
        try:
            for loc in page.locator(sel).all():
                if loc.is_visible():
                    human_hover(page, loc)
                    loc.click()
                    human_sleep(0.25, 0.7)
        except Exception:
            continue

def close_login_modal_if_exists(page: Page) -> bool:
    selectors_modal = [
        "[data-marker='login-form']",
        "[data-marker='registration-form']",
        "div[class*='modal'][class*='auth']",
        "div[class*='modal'] form[action*='login']",
    ]
    for sel in selectors_modal:
        try:
            modals = page.locator(sel)
            for m in modals.all():
                if not m.is_visible():
                    continue
                for btn_sel in [
                    "button[aria-label='–ó–∞–∫—Ä—ã—Ç—å']",
                    "button[data-marker='modal-close']",
                    "button[class*='close']",
                    "button[type='button']",
                ]:
                    btn = m.locator(btn_sel).first
                    if btn and btn.is_enabled():
                        try:
                            human_hover(page, btn)
                            human_sleep(*HUMAN["pre_click_pause_s"])
                            btn.click()
                            human_sleep(*HUMAN["post_click_pause_s"])
                            print("üîí –ú–æ–¥–∞–ª–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–∫—Ä—ã—Ç–∞, –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
                            return True
                        except Exception:
                            pass
                print("üîí –ú–æ–¥–∞–ª–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è ‚Äî –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                return True
        except PWError:
            continue
    return False

def save_phone_png_from_data_uri(data_uri: str, file_stem: str) -> str | None:
    try:
        _, b64_data = data_uri.split(",", 1)
        raw = b64decode(b64_data)
        image = Image.open(BytesIO(raw)).convert("RGB")
        file_name = f"{file_stem}.png"
        out_path = IMG_DIR / file_name
        image.save(out_path)
        print(f"üíæ PNG —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")
        return str(out_path)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ PNG: {e}")
        return None

def get_avito_id_from_url(url: str) -> str:
    m = re.search(r'(\d{7,})', url)
    return m.group(1) if m else str(int(time.time()))

# =========================
# locator-–∫–ª–∏–∫–∏ (–±—ã—Å—Ç—Ä–µ–µ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)
# =========================
def try_click_selector(page: Page, sel: str, timeout: int = 2000) -> bool:
    loc = page.locator(sel).first
    try:
        loc.wait_for(state="visible", timeout=timeout)
        human_sleep(*HUMAN["pre_click_pause_s"])
        loc.click()
        human_sleep(*HUMAN["post_click_pause_s"])
        return True
    except Exception:
        return False

# =========================
# –∫–Ω–æ–ø–∫–∞ ¬´–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω¬ª —á–µ—Ä–µ–∑ locator
# =========================
def click_show_phone_on_ad(page: Page) -> bool:
    human_scroll_jitter(page)

    for anchor in [
        "[data-marker='seller-info']",
        "[data-marker='item-sidebar']",
        "section:has(button[data-marker*='phone'])",
        "section:has(button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å'))",
    ]:
        try:
            page.locator(anchor).first.scroll_into_view_if_needed()
            human_sleep(*HUMAN["scroll_pause_s"])
            break
        except Exception:
            pass

    selector_groups = [
        [
            "button[data-marker='item-phone-button']",
            "button[data-marker='phone-button/number']",
            "button[data-marker*='phone-button']",
        ],
        [
            "button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω')",
            "button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä')",
            "a:has-text('–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω')",
            "a:has-text('–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä')",
        ],
        [
            "button[aria-label*='–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω']",
            "button[aria-label*='–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä']",
        ],
        [
            "[data-marker*='phone'] button",
            "[data-marker*='contacts'] button",
        ],
    ]

    if HUMAN["randomize_selectors"]:
        random.shuffle(selector_groups)
        for g in selector_groups:
            random.shuffle(g)

    for group in selector_groups:
        for sel in group:
            if try_click_selector(page, sel):
                print("üìû –ù–∞–∂–∞–ª–∏ '–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω'.")
                return True

    if try_click_selector(page, "footer:has(button) button"):
        print("üìû –ù–∞–∂–∞–ª–∏ –∫–Ω–æ–ø–∫—É –≤ –ª–∏–ø–∫–æ–º —Ñ—É—Ç–µ—Ä–µ.")
        return True

    print("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ '–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return False

# =========================
# –∫–∞—Ä—Ç–∏–Ω–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —á–µ—Ä–µ–∑ locator
# =========================
def extract_phone_data_uri_on_ad(page: Page) -> str | None:
    loc = page.locator("img[data-marker='phone-image']").first
    try:
        loc.wait_for(state="visible", timeout=1500)
    except Exception:
        print("‚ö†Ô∏è –ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å –Ω–æ–º–µ—Ä–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return None
    try:
        src = loc.get_attribute("src") or ""
    except PWError:
        return None
    if not src.startswith("data:image"):
        print(f"‚ö†Ô∏è src –Ω–µ data:image, –∞: {src[:60]}...")
        return None
    return src

# ========== –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ö–æ–¥–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –∏–∑ Excel/CSV ==========

def read_urls_from_excel_or_csv(
    path: Path,
    sheet: str | int | None = None,
    url_column: str | None = None
) -> list[str]:
    url_re = re.compile(r'https?://(?:www\.)?avito\.ru/[^\s"]+')
    urls: list[str] = []

    if path.suffix.lower() in {".xlsx", ".xls"}:
        xls = pd.ExcelFile(path)
        sheets = [sheet] if sheet is not None else xls.sheet_names
        for sh in sheets:
            df = xls.parse(sh, dtype=str)
            if url_column and url_column in df.columns:
                col = df[url_column].dropna().astype(str)
                urls.extend(col.tolist())
            else:
                for col in df.columns:
                    s = df[col].dropna().astype(str)
                    for val in s:
                        urls.extend(url_re.findall(val))
    elif path.suffix.lower() in {".csv", ".txt"}:
        df = pd.read_csv(path, dtype=str, sep=None, engine="python")
        if url_column and url_column in df.columns:
            col = df[url_column].dropna().astype(str)
            urls.extend(col.tolist())
        else:
            for col in df.columns:
                s = df[col].dropna().astype(str)
                for val in s:
                    urls.extend(url_re.findall(val))
    else:
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .xlsx/.xls/.csv/.txt")

    cleaned = []
    seen = set()
    for u in urls:
        u = u.strip()
        if not u.startswith("http"):
            u = urljoin("https://www.avito.ru", u)
        u = u.split("#", 1)[0]
        u = u.split("?", 1)[0]
        if u not in seen:
            seen.add(u)
            cleaned.append(u)
    return cleaned

# === –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (Windows-friendly) ===

def atomic_write_json(path: Path, data):
    """
    –ù–∞–¥—ë–∂–Ω–∞—è –∑–∞–ø–∏—Å—å –Ω–∞ Windows:
    - —É–Ω–∏–∫–∞–ª—å–Ω—ã–π tmp-—Ñ–∞–π–ª;
    - –¥–æ 10 —Ä–µ—Ç—Ä–∞–µ–≤ os.replace –ø—Ä–∏ PermissionError;
    - –ø—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback –ø—Ä—è–º–æ–π –∑–∞–ø–∏—Å—å—é.
    """
    tmp = path.with_suffix(path.suffix + f".tmp_{int(time.time()*1000)}_{random.randint(1000,9999)}")
    payload = json.dumps(data, ensure_ascii=False, indent=2)
    tmp.write_text(payload, encoding="utf-8")
    attempts = 10
    delay = 0.1
    for _ in range(attempts):
        try:
            os.replace(tmp, path)
            return
        except PermissionError:
            time.sleep(delay)
            delay = min(delay * 1.7, 1.0)
        except Exception:
            time.sleep(delay)
            delay = min(delay * 1.7, 1.0)
    # Fallback
    try:
        path.write_text(payload, encoding="utf-8")
    except Exception as e:
        print(f"‚ùó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")

def load_progress(path: Path) -> dict[str, str]:
    if path.exists():
        try:
            return json.loads(path.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")
    return {}

def load_pending(path: Path) -> list[str]:
    if path.exists():
        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            return [u for u in data if isinstance(u, str)]
        except Exception:
            pass
    return []

def save_pending(path: Path, urls: list[str]):
    unique = sorted(set(urls))
    atomic_write_json(path, unique)

def dump_debug(page: Page, url: str):
    try:
        ad_id = get_avito_id_from_url(url)
        png_path = DEBUG_DIR / f"{ad_id}.png"
        html_path = DEBUG_DIR / f"{ad_id}.html"
        page.screenshot(path=str(png_path), full_page=True)
        html = safe_get_content(page)
        html_path.write_text(html, encoding="utf-8")
        print(f"ü™™ Debug —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {png_path.name}, {html_path.name}")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å debug: {e}")

# --------- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è ---------

NO_CALLS_MARKERS = [
    "–±–µ–∑ –∑–≤–æ–Ω–∫–æ–≤",
    "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è",
]

# –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–º –ø–æ–∑–∂–µ
MODERATION_MARKERS = [
    "–æ–Ω–æ –µ—â—ë –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –µ—â—ë –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
]

# –Ω–∞–≤—Å–µ–≥–¥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ
UNAVAILABLE_MARKERS = [
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ —Å –ø—Ä–æ–¥–∞–∂–∏",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ",
]

def classify_ad_status(page: Page) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: 'ok' | 'no_calls' | 'on_review' | 'unavailable' | 'blocked'
    """
    if is_captcha_or_block(page):
        return "blocked"

    html = safe_get_content(page).lower()

    if any(m in html for m in MODERATION_MARKERS):
        return "on_review"

    if any(m in html for m in UNAVAILABLE_MARKERS):
        return "unavailable"

    if any(m in html for m in NO_CALLS_MARKERS):
        return "no_calls"

    try:
        if page.locator("text=–ë–µ–∑ –∑–≤–æ–Ω–∫–æ–≤").first.is_visible():
            return "no_calls"
    except Exception:
        pass
    return "ok"

# ========== –ü—É–ª –≤–∫–ª–∞–¥–æ–∫ —Å –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ==========

def make_page_pool(context, size: int) -> list[Page]:
    return [context.new_page() for _ in range(size)]

def process_with_pool(context, urls, on_result):
    pages = make_page_pool(context, CONCURRENCY)
    pending_queue = load_pending(PENDING_JSON)

    try:
        it = iter(urls)
        while True:
            batch = []
            # –ù–∞–≤–∏–≥–∞—Ü–∏—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö N —Å—Å—ã–ª–æ–∫ –Ω–∞ —É–∂–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –≤–∫–ª–∞–¥–∫–∞—Ö
            for p in pages:
                try:
                    url = next(it)
                except StopIteration:
                    # —Å–æ—Ö—Ä–∞–Ω–∏–º –æ—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º
                    save_pending(PENDING_JSON, pending_queue)
                    return
                batch.append((url, p))
                try:
                    # –±—ã—Å—Ç—Ä–µ–µ: domcontentloaded
                    p.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
                except PWTimeoutError:
                    print(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç: {url}")
                    continue
                human_sleep(0.2, 0.6)
                human_scroll_jitter(p, count=random.randint(1, 2))

            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è/–º–æ–¥–∞–ª–∫–∏/–∫–ª–∏–∫
            for url, p in batch:
                status = classify_ad_status(p)
                if status == "blocked":
                    print(f"üö´ –ö–∞–ø—á–∞/–±–ª–æ–∫ –Ω–∞ {url}")
                    continue
                if status == "on_review":
                    print(f"‚è≥ –ù–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ: {url}")
                    on_result(url, "__SKIP_ON_REVIEW__")
                    pending_queue.append(url)
                    continue
                if status == "unavailable":
                    print(f"‚è≠Ô∏è –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ/–∑–∞–∫—Ä—ã—Ç–æ: {url}")
                    on_result(url, "__SKIP_UNAVAILABLE__")
                    continue
                if status == "no_calls":
                    print(f"‚è≠Ô∏è –ë–µ–∑ –∑–≤–æ–Ω–∫–æ–≤: {url}")
                    on_result(url, "__SKIP_NO_CALLS__")
                    continue

                close_city_or_cookie_modals(p)
                if not click_show_phone_on_ad(p):
                    # –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
                    status2 = classify_ad_status(p)
                    if status2 == "on_review":
                        on_result(url, "__SKIP_ON_REVIEW__")
                        pending_queue.append(url)
                    elif status2 == "unavailable":
                        on_result(url, "__SKIP_UNAVAILABLE__")
                    elif status2 == "no_calls":
                        on_result(url, "__SKIP_NO_CALLS__")
                    else:
                        dump_debug(p, url)

            # –ñ–¥—ë–º –æ—Ç—Ä–∏—Å–æ–≤–∫—É –∫–∞—Ä—Ç–∏–Ω–æ–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
            human_sleep(*HUMAN["click_delay_jitter"])

            # –°–±–æ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫
            for url, p in batch:
                if close_login_modal_if_exists(p) or is_captcha_or_block(p):
                    continue
                data_uri = extract_phone_data_uri_on_ad(p)
                if not data_uri:
                    continue

                if SAVE_DATA_URI:
                    value = data_uri
                else:
                    avito_id = get_avito_id_from_url(url)
                    out_path = save_phone_png_from_data_uri(data_uri, avito_id)
                    if not out_path:
                        continue
                    value = out_path

                on_result(url, value)
                print(f"‚úÖ {url} -> {'[data:image...]' if SAVE_DATA_URI else value}")

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞—Ä—Ç–∏—è–º–∏ (–∞–Ω—Ç–∏–±–∞–Ω)
            human_sleep(*PAGE_DELAY_BETWEEN_BATCHES)

    finally:
        save_pending(PENDING_JSON, pending_queue)
        for p in pages:
            try:
                p.close()
            except Exception:
                pass

# ========== –û–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∞ ¬´–Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏¬ª ==========

def recheck_pending_once(context, on_result):
    if not PENDING_RECHECK:
        return
    pend = load_pending(PENDING_JSON)
    if not pend:
        return

    pend = pend[:PENDING_RECHECK_LIMIT]
    print(f"\nüîÅ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏: {len(pend)}")

    page = context.new_page()
    still_pending = []

    for url in pend:
        try:
            page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
        except Exception:
            still_pending.append(url)
            continue

        st = classify_ad_status(page)
        if st == "ok":
            close_city_or_cookie_modals(page)
            if click_show_phone_on_ad(page):
                time.sleep(random.uniform(*HUMAN["click_delay_jitter"]))
                data_uri = extract_phone_data_uri_on_ad(page)
                if data_uri:
                    if SAVE_DATA_URI:
                        on_result(url, data_uri)
                    else:
                        out = save_phone_png_from_data_uri(data_uri, get_avito_id_from_url(url))
                        if out:
                            on_result(url, out)
                    print(f"‚úÖ (–ø–æ–≤—Ç–æ—Ä) {url}")
                else:
                    still_pending.append(url)
            else:
                st2 = classify_ad_status(page)
                if st2 == "no_calls":
                    on_result(url, "__SKIP_NO_CALLS__")
                elif st2 == "on_review":
                    still_pending.append(url)
                else:
                    on_result(url, "__SKIP_UNAVAILABLE__")
        elif st == "on_review":
            still_pending.append(url)
        elif st == "no_calls":
            on_result(url, "__SKIP_NO_CALLS__")
        else:
            on_result(url, "__SKIP_UNAVAILABLE__")

        time.sleep(random.uniform(*PENDING_RECHECK_WAIT))

    try:
        page.close()
    except Exception:
        pass
    save_pending(PENDING_JSON, still_pending)
    print(f"‚ÑπÔ∏è –í –æ—á–µ—Ä–µ–¥–∏ –æ—Å—Ç–∞–ª–æ—Å—å: {len(still_pending)}")

# ========== –û–°–ù–û–í–ù–û–ô –°–¶–ï–ù–ê–†–ò–ô ==========

def main():
    urls = read_urls_from_excel_or_csv(INPUT_FILE, INPUT_SHEET, URL_COLUMN)
    urls = urls[:TEST_TOTAL]

    phones_map: dict[str, str] = load_progress(OUT_JSON)
    already_done = set(phones_map.keys())
    urls = [u for u in urls if u not in already_done]

    print(f"üîé –ù–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(urls)} (—É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ä–∞–Ω–µ–µ: {len(already_done)})")
    if not urls:
        print(f"‚ÑπÔ∏è –ù–µ—á–µ–≥–æ –¥–µ–ª–∞—Ç—å. –ü—Ä–æ–≥—Ä–µ—Å—Å –≤ {OUT_JSON}: {len(phones_map)} –∑–∞–ø–∏—Å–µ–π.")
        return

    def flush_progress():
        try:
            atomic_write_json(OUT_JSON, phones_map)
        except Exception as e:
            print(f"‚ùó –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")

    atexit.register(flush_progress)
    try:
        signal.signal(signal.SIGINT, lambda *a: (flush_progress(), exit(1)))
    except Exception:
        pass
    try:
        signal.signal(signal.SIGTERM, lambda *a: (flush_progress(), exit(1)))
    except Exception:
        pass

    with sync_playwright() as p:
        launch_kwargs = {
            "headless": HEADLESS,
            "args": [
                "--disable-blink-features=AutomationControlled",
                "--start-maximized",
            ],
        }
        if USE_PROXY:
            launch_kwargs["proxy"] = {
                "server": f"http://{PROXY_HOST}:{PROXY_PORT}",
                "username": PROXY_LOGIN,
                "password": PROXY_PASSWORD,
            }

        browser = p.chromium.launch(**launch_kwargs)

        # –ß—É—Ç—å —Ä–∞–Ω–¥–æ–º–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –≤—å—é–ø–æ—Ä—Ç–∞
        vp_w = random.randint(1200, 1368)
        vp_h = random.randint(760, 900)

        context = browser.new_context(
            viewport={"width": vp_w, "height": vp_h},
            user_agent=UA,
        )
        context.set_default_navigation_timeout(NAV_TIMEOUT)
        context.set_default_timeout(NAV_TIMEOUT)

        # –†—É—á–Ω–æ–π –ª–æ–≥–∏–Ω –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Å—ã–ª–∫–µ
        page = context.new_page()
        first_url = urls[0]
        try:
            page.goto(first_url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
        except PWTimeoutError:
            pass

        print("\nüîë –¢–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è:")
        print("   ‚Ä¢ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞–ø—á–∞ ‚Äî —Ä–µ—à–∏;")
        print("   ‚Ä¢ –∑–∞–ª–æ–≥–∏–Ω—å—Å—è –≤ –ê–≤–∏—Ç–æ;")
        print("   ‚Ä¢ –æ—Å—Ç–∞–≤—å –æ—Ç–∫—Ä—ã—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è.")
        input("üëâ –ì–æ—Ç–æ–≤? –ù–∞–∂–º–∏ Enter –≤ –∫–æ–Ω—Å–æ–ª–∏.\n")

        if is_captcha_or_block(page):
            print("‚ùå –í—Å—ë –µ—â—ë –∫–∞–ø—á–∞/–±–ª–æ–∫ ‚Äî –≤—ã—Ö–æ–¥–∏–º.")
            browser.close()
            flush_progress()
            return

        try:
            page.close()
        except Exception:
            pass

        def on_result(url: str, value: str):
            # value ‚Äî –ª–∏–±–æ data:image..., –ª–∏–±–æ –ø—É—Ç—å –∫ PNG, –ª–∏–±–æ __SKIP_...
            phones_map[url] = value
            atomic_write_json(OUT_JSON, phones_map)  # –Ω–∞–¥—ë–∂–Ω–æ –∏ —Å—Ä–∞–∑—É

        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ö–æ–¥ –ø–æ —Å—Å—ã–ª–∫–∞–º —Å –ø—É–ª–æ–º –≤–∫–ª–∞–¥–æ–∫
        try:
            process_with_pool(context, urls, on_result)
        except KeyboardInterrupt:
            print("‚èπ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            flush_progress()

        # –û–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∞ ¬´–Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏¬ª
        recheck_pending_once(context, on_result)

        browser.close()
        flush_progress()

        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ. –í {OUT_JSON} —Å–µ–π—á–∞—Å {len(phones_map)} –∑–∞–ø–∏—Å–µ–π.")
        if not SAVE_DATA_URI:
            print(f"üìÇ PNG –ª–µ–∂–∞—Ç –≤ {IMG_DIR}")

if __name__ == "__main__":
    main()
